{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a72dd2-4e24-4ede-bd17-7b85baa92ace",
   "metadata": {},
   "source": [
    "# Exploratória / Distribuições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d9795f-3de6-4114-a8e4-2d5d4cb3cb65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature: MonthlyCharges                      |███████████████████████████████████▏     | [ 86%]   00:19 -> (00:03 left)\n",
      "Done! Use 'show' commands to display/save.   |█████████████████████████████████████████| [100%]   00:01 -> (00:00 left)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report telco_customer_churn_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "\n",
    "# Carregar o dataset (substitua pelo seu próprio dataset)\n",
    "# Exemplo: carregando um dataset de churn\n",
    "url = '../env/dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "data = data.drop('tenure', axis='columns')\n",
    "data = data.drop('MonthlyCharges', axis='columns')\n",
    "\n",
    "# Gerar o relatório de análise do dataset com Sweetviz\n",
    "report = sv.analyze(data)\n",
    "\n",
    "# Gerar o arquivo HTML com o relatório\n",
    "report.show_html('telco_customer_churn_report.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b77d0d-9494-4e4c-a1ef-48ea486cdec0",
   "metadata": {},
   "source": [
    "# 1. Importação das Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8cb1f-9750-4bb5-83a5-399e4ec0599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para dividir os dados e avaliar o modelo\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Algoritmos de Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Ignorar avisos\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad76ad4-48a2-4136-b91d-93ba777a2199",
   "metadata": {},
   "source": [
    "# 2. Carregamento e Exploração Inicial dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640c06c-1b43-436c-8c99-84e246b6b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "data = pd.read_csv('../env/dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(\"Amostra dos dados:\")\n",
    "display(data.head())\n",
    "\n",
    "# Informações sobre o dataset\n",
    "print(\"\\nInformações sobre o dataset:\")\n",
    "data.info()\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f40546-dff9-4c0b-963b-dcbb3e820bc2",
   "metadata": {},
   "source": [
    "# 3. Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabaaa3-ee1b-4e09-b86a-80ca2ae3102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Tratamento de valores ausentes\n",
    "# 'TotalCharges' está como objeto, precisamos converter para numérico\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723740eb-8027-473e-8781-4b31d6e214ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas com 'TotalCharges' nulo\n",
    "data.dropna(subset=['TotalCharges'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077729d-dc76-4bad-b38b-e0570eea1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2. Remover colunas irrelevantes\n",
    "data.drop(['customerID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddafb8ee-592c-46ce-99d7-43887e989b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3. Separar variáveis por tipo\n",
    "# Variáveis numéricas\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abfa14-5c5e-426f-b9d8-5b7ef53ea731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável alvo\n",
    "target_col = 'Churn'\n",
    "\n",
    "# Variáveis categóricas (excluindo a variável alvo)\n",
    "categorical_cols = data.drop(columns=numeric_cols + [target_col]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3f7e6-8172-4ef8-9419-0a35e1a42104",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3468cb3-4e20-42ad-9d5d-52c99235e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4. Dividir X e y\n",
    "X = data.drop(target_col, axis=1)\n",
    "y = data[target_col].map({'Yes': 1, 'No': 0})  # Mapear a variável alvo para 0 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a40033-2c34-4db6-978f-5f671186ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5. Pré-processamento usando Pipeline\n",
    "# Pipeline para as variáveis categóricas\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1b107-cf02-45eb-8797-a97970a71122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para as variáveis numéricas\n",
    "numeric_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b95a07-603d-4f6f-a4d5-8cfbc2758aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar os transformadores usando ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Criar o Pipeline completo\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369891be-ab01-466e-a7d6-7081065d96ed",
   "metadata": {},
   "source": [
    "# 4. Divisão dos Dados em Conjunto de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee87308-d3bf-4f20-a1d5-1bd2dd12f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad943c9-e385-4065-adf7-f70b60d51a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTamanho do conjunto de treinamento: {X_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a939c3-d1a6-44ad-9798-b80a565223c1",
   "metadata": {},
   "source": [
    "# 5. Treinamento e Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b685bb-0ea5-431e-9b96-1dc8c3de054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    print(f\"Acurácia: {acc:.4f}\")\n",
    "    print(f\"Precisão: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Matriz de Confusão - {model_name}')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "    \n",
    "    # Curva ROC e AUC\n",
    "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
    "    plt.plot([0,1], [0,1], linestyle='--')\n",
    "    plt.title(f'Curva ROC - {model_name}')\n",
    "    plt.xlabel('Taxa de Falsos Positivos')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9be5df-e10d-48ab-9314-1a3b2b14f0ac",
   "metadata": {},
   "source": [
    "### 5.1. Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214eef9-b089-4238-b5d4-9e63a56b645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_lr = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32763444-582b-4094-924b-fc03f9ac6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr.fit(X_train, y_train)\n",
    "evaluate_model(clf_lr, X_test, y_test, \"Regressão Logística\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc177c7-f045-486e-a761-76d5a659af7c",
   "metadata": {},
   "source": [
    "### 5.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4dc82-c261-4d1c-9eca-93767e29431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b86756-d618-4345-9d1b-7f9077294e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.fit(X_train, y_train)\n",
    "evaluate_model(clf_rf, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bacf26-19f6-4aaa-a88e-37f39c2adb7c",
   "metadata": {},
   "source": [
    "### 5.3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee8a91-1a29-47bf-bedb-21e1a0636747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "evaluate_model(clf_xgb, X_test, y_test, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec2969-3929-4ef3-916b-c2d3edbec10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Otimização de Hiperparâmetros para Random Forest\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf_rf, param_grid=param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4eb7a5-c3d4-4ea2-bb5f-37bbda62977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nMelhores parâmetros para Random Forest: {grid_search.best_params_}\")\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Avaliar modelo otimizado\n",
    "evaluate_model(best_rf, X_test, y_test, \"Random Forest Otimizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d424bf-c270-4a7c-9d0a-9a466d244373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 7. Conclusões e Próximos Passos\n",
    "print(\"\"\"\n",
    "Conclusões:\n",
    "- Identificamos que o modelo Random Forest Otimizado apresenta o melhor desempenho em termos de F1-Score.\n",
    "- As variáveis mais importantes para a previsão de churn podem ser investigadas a partir do modelo treinado.\n",
    "\n",
    "Próximos Passos:\n",
    "- Implementar técnicas de balanceamento de classes se necessário (e.g., SMOTE).\n",
    "- Explorar modelos adicionais ou ensemble de modelos.\n",
    "- Implementar o modelo em produção utilizando AWS SageMaker.\n",
    "- Monitorar o desempenho do modelo e atualizá-lo periodicamente.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e0c0e-f6b0-4fb0-889f-7e3aa256db44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea787fa-5b28-4082-889e-531685c3b30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
